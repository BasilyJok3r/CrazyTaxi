{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "step = 1\n",
    "\n",
    "canvas = np.zeros((1000, 1000, 3), np.uint8)\n",
    "target_pos = [[300, 300], [400, 400]]\n",
    "car_pos = 0\n",
    "\n",
    "\n",
    "def car_init():\n",
    "    global car_pos, target_pos\n",
    "    x_pos_rand = random.randint(0, 900)\n",
    "    y_pos_rand = random.randint(0, 900)\n",
    "    x1_y1 = (x_pos_rand, y_pos_rand)\n",
    "    x2_y2 = (x_pos_rand + 100, y_pos_rand + 100)\n",
    "    car_pos = (x1_y1, x2_y2)\n",
    "    x_pos_rand = random.randint(0, 900)\n",
    "    y_pos_rand = random.randint(0, 900)\n",
    "    x1_y1 = (x_pos_rand, y_pos_rand)\n",
    "    x2_y2 = (x_pos_rand + 100, y_pos_rand + 100)\n",
    "    target_pos = (x1_y1, x2_y2)\n",
    "    _,car_center,target_center = get_car_status(car_pos, target_pos)\n",
    "    return car_center, target_center\n",
    "\n",
    "\n",
    "def get_car_status(cp, tg):\n",
    "    center_car = (int((cp[0][0] + cp[1][0]) / 2), int((cp[0][1] + cp[1][1]) / 2))\n",
    "    center_target = (int((tg[0][0] + tg[1][0]) / 2), int((tg[0][1] + tg[1][1]) / 2))\n",
    "    distance = int(math.sqrt((center_target[0] - center_car[0])**2 + (center_target[1] - center_car[1])**2))\n",
    "\n",
    "    return distance, center_car, center_target\n",
    "\n",
    "def get_car_distance():\n",
    "    d, _, _ = get_car_status(car_pos, target_pos)\n",
    "    return d\n",
    "\n",
    "def car_mov(msg):\n",
    "#     print(msg)\n",
    "    global car_pos\n",
    "    global canvas, cur_reward\n",
    "\n",
    "    x_y_adjust = [0, 0]\n",
    "    \n",
    "    if msg == 0:  # forward\n",
    "        x_y_adjust = 0, step\n",
    "    elif msg == 1:  # backward\n",
    "        x_y_adjust = 0, -step\n",
    "    elif msg == 2:  # right forward\n",
    "        x_y_adjust = step, step\n",
    "    elif msg == 3:  # left forward\n",
    "        x_y_adjust = -step, step\n",
    "    elif msg == 4:  # right backward\n",
    "        x_y_adjust = step, -step\n",
    "    elif msg == 5:  # left backward\n",
    "        x_y_adjust = -step, -step\n",
    "    elif msg == 6:  # stop\n",
    "        x_y_adjust = 0, 0\n",
    "\n",
    "    updated_x_y_1 = car_pos[0][0] + x_y_adjust[0], car_pos[0][1] + x_y_adjust[1]\n",
    "    updated_x_y_2 = car_pos[1][0] + x_y_adjust[0], car_pos[1][1] + x_y_adjust[1]\n",
    "\n",
    "    car_pos = (updated_x_y_1, updated_x_y_2)\n",
    "\n",
    "    canvas = np.zeros((1000, 1000, 3), np.uint8)\n",
    "    canvas = cv2.rectangle(canvas, target_pos[0], target_pos[1], (0, 0, 255), -1)\n",
    "    canvas = cv2.rectangle(canvas, car_pos[0], car_pos[1], (0, 255, 0))\n",
    "\n",
    "    distance, car_center, target_center = get_car_status(car_pos, target_pos)\n",
    "\n",
    "    cv2.circle(canvas, car_center, 10, (0, 255, 255), -1)\n",
    "    cv2.circle(canvas, target_center, 10, (0, 255, 255), -1)\n",
    "    cv2.line(canvas, car_center, target_center, (255, 255, 0), thickness=5)\n",
    "    cv2.putText(canvas, 'dis: ' + str(distance), (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 50), 2, cv2.LINE_AA)\n",
    "    cv2.putText(canvas, 'reward: ' + str(cur_reward), (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 50), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('img', canvas)\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    _,car_center,target_center = get_car_status(car_pos, target_pos)\n",
    "    return car_center, target_center  \n",
    "\n",
    "\n",
    "# car_init()\n",
    "# car_mov(2)\n",
    "# car_mov(2)\n",
    "# car_mov(2)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ard_write(x):\n",
    "    arduino.write(bytes(str(x), 'utf-8'))\n",
    "\n",
    "def ard_read():\n",
    "    ard_write('s')\n",
    "    data = arduino.readline()[:-2]\n",
    "    return int(data.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arduino' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b36eb0e84cf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0marduino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'arduino' is not defined"
     ]
    }
   ],
   "source": [
    "del arduino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import sleep\n",
    "# import numpy as np\n",
    "\n",
    "# reward_step = 5\n",
    "# global cur_reward\n",
    "# class Crazy_Taxi(Env):\n",
    "#     def __init__(self):\n",
    "#         global cur_reward\n",
    "#         self.action_space = Discrete(7)\n",
    "#         # f, b, fr, fl, br, bl, Stop\n",
    "#         # 1, 2, 3, 4, 5, 6, 7\n",
    "#         low = np.zeros(4)\n",
    "#         high = np.ones(4) * 1000\n",
    "#         self.observation_space = Box(low=low, high=high, dtype=int)\n",
    "#         self.statetmp = car_init() # return xc, yc, xt, yt\n",
    "#         (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "#         self.distance = get_car_distance()\n",
    "#         self.last_distance = self.distance\n",
    "#         self.episode_length = 100\n",
    "#         cur_reward = 0\n",
    "\n",
    "                \n",
    "#     def step(self, action):\n",
    "#         global cur_reward\n",
    "\n",
    "# #         print(action)\n",
    "#         self.episode_length -= 1\n",
    "# #         self.state = car_mov(action)\n",
    "        \n",
    "#         self.statetmp = car_mov(action) # return xc, yc, xt, yt\n",
    "#         (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "        \n",
    "#         self.distance = get_car_distance()\n",
    "#         if(self.distance == 0):\n",
    "#             reward = reward_step\n",
    "            \n",
    "#         elif(self.distance < self.last_distance):\n",
    "#             reward = reward_step \n",
    "#         else:\n",
    "#             reward = -reward_step\n",
    "            \n",
    "#         cur_reward+=reward\n",
    "        \n",
    "#         if self.episode_length == 0 :\n",
    "#             done = True\n",
    "#         else:\n",
    "#             done = False\n",
    "        \n",
    "#         self.last_distance = self.distance\n",
    "        \n",
    "#         return self.state, reward, done, {}\n",
    "\n",
    "#     def render(self):\n",
    "#         # Implement viz\n",
    "#         pass\n",
    "    \n",
    "#     def reset(self):\n",
    "#         global cur_reward\n",
    "#         self.episode_length = 100\n",
    "#         self.statetmp = car_init() # return xc, yc, xt, yt\n",
    "#         (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "#         self.distance = get_car_distance()\n",
    "#         self.last_distance = self.distance\n",
    "#         cur_reward = 0\n",
    "#         return self.state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import numpy as np\n",
    "\n",
    "reward_step = 1\n",
    "l = 1\n",
    "global cur_reward\n",
    "class Crazy_Taxi(Env):\n",
    "    def __init__(self):\n",
    "        global cur_reward, l\n",
    "        self.action_space = Discrete(7)\n",
    "        # f, b, fr, fl, br, bl, Stop\n",
    "        # 1, 2, 3, 4, 5, 6, 7\n",
    "        low = np.zeros(2) * -1\n",
    "        high = np.ones(2) * 1\n",
    "        self.observation_space = Box(low=low, high=high, dtype=int)\n",
    "        self.statetmp = car_init() # return xc, yc, xt, yt\n",
    "        (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "        self.arr = np.array([self.xc, self.yc, self.xt, self.yt], dtype=float)\n",
    "        self.norm = np.linalg.norm(self.arr)\n",
    "        self.na = self.arr/self.norm\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "        self.state = self.na[0],self.na[1],self.na[2],self.na[3]\n",
    "        self.distance = get_car_distance()\n",
    "        self.last_distance = self.distance\n",
    "        self.last_state = self.state\n",
    "#         print(\"is\",self.state)\n",
    "#         print(\"il\",self.last_state)\n",
    "        self.state_v2 = self.na[0]-self.na[2], self.na[1]-self.na[3]\n",
    "        self.episode_length = l\n",
    "        cur_reward = 0\n",
    "\n",
    "                \n",
    "    def step(self, action):\n",
    "        global cur_reward\n",
    "        reward = 0\n",
    "#         print(action)\n",
    "        self.episode_length -= 1\n",
    "#         self.state = car_mov(action)\n",
    "        \n",
    "        self.statetmp = car_mov(action) # return xc, yc, xt, yt\n",
    "        (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "        \n",
    "        self.arr = np.array([self.xc, self.yc, self.xt, self.yt], dtype=float)\n",
    "        self.norm = np.linalg.norm(self.arr)\n",
    "        self.na = self.arr/self.norm\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "        self.state = self.na[0],self.na[1],self.na[2],self.na[3]\n",
    "        self.state_v2 = self.na[0]-self.na[2], self.na[1]-self.na[3]\n",
    "               \n",
    "        \n",
    "        lxc, lyc, lxt, lyt = self.last_state\n",
    "#         print(\"s\",self.state)\n",
    "#         print(\"l\",self.last_state)\n",
    "        self.distance = get_car_distance()\n",
    "        reward = self.last_distance - self.distance\n",
    "        if(reward == 0 and self.distance <= step):\n",
    "            reward += 10\n",
    "        cur_reward+=reward\n",
    "        \n",
    "        if self.episode_length == 0 :\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        self.last_distance = self.distance\n",
    "        self.last_state = self.state\n",
    "        \n",
    "        return self.state_v2, reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        global cur_reward, l\n",
    "        self.episode_length = l\n",
    "        self.statetmp = car_init() # return xc, yc, xt, yt\n",
    "        (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "        \n",
    "        self.arr = np.array([self.xc, self.yc, self.xt, self.yt], dtype=float)\n",
    "        self.norm = np.linalg.norm(self.arr)\n",
    "        self.na = self.arr/self.norm\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "        self.state = self.na[0],self.na[1],self.na[2],self.na[3]\n",
    "        self.distance = get_car_distance()\n",
    "        self.last_distance = self.distance\n",
    "        self.last_state = self.state\n",
    "        self.distance = get_car_distance()\n",
    "        self.last_distance = self.distance\n",
    "        self.state_v2 = self.na[0]-self.na[2], self.na[1]-self.na[3]\n",
    "        cur_reward = 0\n",
    "        return self.state_v2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import sleep\n",
    "# import numpy as np\n",
    "\n",
    "# reward_step = 5\n",
    "# global cur_reward\n",
    "# class Crazy_Taxi(Env):\n",
    "#     def __init__(self):\n",
    "#         global cur_reward\n",
    "#         self.action_space = Discrete(7)\n",
    "#         # f, b, fr, fl, br, bl, Stop\n",
    "#         # 1, 2, 3, 4, 5, 6, 7\n",
    "#         low = np.zeros(4)\n",
    "#         high = np.ones(4) * 1000\n",
    "#         self.observation_space = Box(low=low, high=high, dtype=int)\n",
    "#         self.statetmp = car_init() # return xc, yc, xt, yt\n",
    "#         (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "#         self.distance = get_car_distance()\n",
    "#         self.last_distance = self.distance\n",
    "#         self.episode_length = 1\n",
    "#         cur_reward = 0\n",
    "\n",
    "                \n",
    "#     def step(self, action):\n",
    "#         global cur_reward\n",
    "\n",
    "# #         print(action)\n",
    "#         self.episode_length -= 1\n",
    "# #         self.state = car_mov(action)\n",
    "        \n",
    "#         self.statetmp = car_mov(action) # return xc, yc, xt, yt\n",
    "#         (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "        \n",
    "#         self.distance = get_car_distance()\n",
    "#         if(self.distance == 0):\n",
    "#             reward = reward_step\n",
    "            \n",
    "#         elif(self.distance < self.last_distance):\n",
    "#             reward = reward_step \n",
    "#         else:\n",
    "#             reward = -reward_step\n",
    "            \n",
    "#         cur_reward+=reward\n",
    "        \n",
    "#         if self.episode_length == 0 :\n",
    "#             done = True\n",
    "#         else:\n",
    "#             done = False\n",
    "        \n",
    "#         self.last_distance = self.distance\n",
    "        \n",
    "#         return self.state, reward, done, {}\n",
    "\n",
    "#     def render(self):\n",
    "#         # Implement viz\n",
    "#         pass\n",
    "    \n",
    "#     def reset(self):\n",
    "#         global cur_reward\n",
    "#         self.episode_length = 1\n",
    "#         self.statetmp = car_init() # return xc, yc, xt, yt\n",
    "#         (self.xc, self.yc), (self.xt, self.yt) = self.statetmp\n",
    "#         self.state = self.xc, self.yc, self.xt, self.yt\n",
    "#         self.distance = get_car_distance()\n",
    "#         self.last_distance = self.distance\n",
    "#         cur_reward = 0\n",
    "#         return self.state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Crazy_Taxi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5087070304212464, 0.5458555318976117)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.episode_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6792868841392501,\n",
       " 0.6974820685358372,\n",
       " 0.17057985371800366,\n",
       " 0.15162653663822548)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5087070304212464, 0.5458555318976117)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "import keras\n",
    "from keras.optimizers import adam_v2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(-0.09652740733395049, -0.049522756806113705) 1 True {}\n",
      "Episode:1 Score:1\n",
      "1\n",
      "(0.5716726737274942, 0.05104220301138346) 0 True {}\n",
      "Episode:2 Score:0\n",
      "5\n",
      "(0.43285961951232127, 0.17461428387970496) 2 True {}\n",
      "Episode:3 Score:2\n",
      "6\n",
      "(0.3894316468388741, 0.38108668297804105) 0 True {}\n",
      "Episode:4 Score:0\n",
      "6\n",
      "(0.28949976275792094, 0.5461421904788999) 0 True {}\n",
      "Episode:5 Score:0\n",
      "6\n",
      "(0.14019197051836535, 0.11432321405366708) 0 True {}\n",
      "Episode:6 Score:0\n",
      "0\n",
      "(0.4523526934047183, -0.49574383905505104) 1 True {}\n",
      "Episode:7 Score:1\n",
      "6\n",
      "(-0.10004566325796499, 0.04081863060924967) 0 True {}\n",
      "Episode:8 Score:0\n",
      "2\n",
      "(0.2197669932890336, -0.30415751871202246) 1 True {}\n",
      "Episode:9 Score:1\n",
      "2\n",
      "(0.34022332795575067, 0.2965030404848014) -1 True {}\n",
      "Episode:10 Score:-1\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        #env.render() ## lol sha8al ! :)))))))))\n",
    "        action = env.action_space.sample()\n",
    "        print(action)\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        print(n_state, reward, done, info)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(24, activation='sigmoid', input_shape=(1,2)))\n",
    "    model.add(Dense(24, activation='sigmoid'))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(7, activation='softmax'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 24)             72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 24)             600       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 10)             250       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 999\n",
      "Trainable params: 999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Princ\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11/10000 [..............................] - ETA: 1:47 - reward: 0.1818  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Princ\\anaconda3\\lib\\site-packages\\rl\\memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9364/10000 [===========================>..] - ETA: 23s - reward: 0.5587"
     ]
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(adam_v2.Adam(lr=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=100000, visualize=False, verbose=1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 3395/10000 [=========>....................] - ETA: 2:18 - reward: 1.2837done, took 74.303 seconds\n"
     ]
    }
   ],
   "source": [
    "# dqn = build_agent(model, actions)\n",
    "# dqn.compile(adam_v2.Adam(lr=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights(\"best2.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = env.action_space.n\n",
    "states = env.observation_space.shape[0]\n",
    "model = build_model(states, actions)\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(adam_v2.Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('best.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  213/10000 [..............................] - ETA: 4:48 - reward: 6.1408done, took 6.327 seconds\n"
     ]
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=10000, visualize=False, verbose=1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 100 episodes ...\n",
      "Episode 1: reward: 272.000, steps: 500\n",
      "Episode 2: reward: 263.000, steps: 500\n",
      "Episode 3: reward: 624.000, steps: 500\n"
     ]
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=100, visualize=False)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"x.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"24-10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(ard_read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-bc5dd222802a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_shape' is not defined"
     ]
    }
   ],
   "source": [
    "len(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 8]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((None, actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ard_write('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
